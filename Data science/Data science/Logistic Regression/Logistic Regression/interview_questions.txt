1. What is the difference between precision and recall?

Precision tells us how many of the results we predicted as positive were actually correct.
 Example: If your model says 10 emails are spam, and only 7 are really spam, precision is 7 out of 10.

Recall tells us how many of the actual positive cases we were able to find.
 Example: If there are 20 spam emails and your model catches only 7, recall is 7 out of 20.

 So:

Precision = “How accurate are the positive predictions?”

Recall = “How many actual positives did we find?”

2. What is cross-validation, and why is it important in binary classification?

Cross-validation is a way to test how good your model really is by trying it on different parts of the data.

In simple steps:

You split your data into small parts (like slices).

Train the model on some parts and test it on the others.

Repeat this a few times and take the average result.

 Why it’s useful:

It helps make sure your model works well on new data, not just on what it already saw.

It helps avoid mistakes like your model being too confident or too weak.